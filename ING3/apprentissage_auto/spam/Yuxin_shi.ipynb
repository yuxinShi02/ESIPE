{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`23/11/2018 Yuxin SHI`\n",
    "# Apprentissage automatique\n",
    "A l'aide des méthodes vues en cours, et à partir des données disponibles, proposer au moins trois classifieurs (prédicteur de SPAM). Vous prendrez soin de détailler toutes les démarches faite pour construire le classifieur notamment:\n",
    "\n",
    "Choix de la méthode.\n",
    "Calibration et éventuel choix des variables utilisées.\n",
    "Estimation de la qualité de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_freq_make</th>\n",
       "      <th>Word_freq_address</th>\n",
       "      <th>Word_freq_all</th>\n",
       "      <th>Word_freq_3d</th>\n",
       "      <th>Word_freq_our</th>\n",
       "      <th>Word_freq_over</th>\n",
       "      <th>Word_freq_remove</th>\n",
       "      <th>Word_freq_internet</th>\n",
       "      <th>Word_freq_order</th>\n",
       "      <th>Word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>Char_freq1</th>\n",
       "      <th>Char_freq2</th>\n",
       "      <th>Char_freq3</th>\n",
       "      <th>Char_freq4</th>\n",
       "      <th>Char_freq5</th>\n",
       "      <th>Char_freq6</th>\n",
       "      <th>Capital_run_length_average</th>\n",
       "      <th>Capital_run_length_longest</th>\n",
       "      <th>Capital_run_length_total</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.671</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.022</td>\n",
       "      <td>9.744</td>\n",
       "      <td>445</td>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.312</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.243</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word_freq_make  Word_freq_address  Word_freq_all  Word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "5            0.00               0.00           0.00           0.0   \n",
       "6            0.15               0.00           0.46           0.0   \n",
       "7            0.06               0.12           0.77           0.0   \n",
       "8            0.00               0.00           0.00           0.0   \n",
       "9            0.00               0.00           0.25           0.0   \n",
       "\n",
       "   Word_freq_our  Word_freq_over  Word_freq_remove  Word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           0.63            0.00              0.31                0.63   \n",
       "3           1.85            0.00              0.00                1.85   \n",
       "4           1.92            0.00              0.00                0.00   \n",
       "5           1.88            0.00              0.00                1.88   \n",
       "6           0.61            0.00              0.30                0.00   \n",
       "7           0.19            0.32              0.38                0.00   \n",
       "8           0.00            0.00              0.96                0.00   \n",
       "9           0.38            0.25              0.25                0.00   \n",
       "\n",
       "   Word_freq_order  Word_freq_mail  ...   Char_freq1  Char_freq2  Char_freq3  \\\n",
       "0             0.00            0.00  ...        0.000       0.000         0.0   \n",
       "1             0.00            0.94  ...        0.000       0.132         0.0   \n",
       "2             0.31            0.63  ...        0.000       0.135         0.0   \n",
       "3             0.00            0.00  ...        0.000       0.223         0.0   \n",
       "4             0.00            0.64  ...        0.000       0.054         0.0   \n",
       "5             0.00            0.00  ...        0.000       0.206         0.0   \n",
       "6             0.92            0.76  ...        0.000       0.271         0.0   \n",
       "7             0.06            0.00  ...        0.040       0.030         0.0   \n",
       "8             0.00            1.92  ...        0.000       0.000         0.0   \n",
       "9             0.00            0.00  ...        0.022       0.044         0.0   \n",
       "\n",
       "   Char_freq4  Char_freq5  Char_freq6  Capital_run_length_average  \\\n",
       "0       0.778       0.000       0.000                       3.756   \n",
       "1       0.372       0.180       0.048                       5.114   \n",
       "2       0.135       0.000       0.000                       3.537   \n",
       "3       0.000       0.000       0.000                       3.000   \n",
       "4       0.164       0.054       0.000                       1.671   \n",
       "5       0.000       0.000       0.000                       2.450   \n",
       "6       0.181       0.203       0.022                       9.744   \n",
       "7       0.244       0.081       0.000                       1.729   \n",
       "8       0.462       0.000       0.000                       1.312   \n",
       "9       0.663       0.000       0.000                       1.243   \n",
       "\n",
       "   Capital_run_length_longest  Capital_run_length_total  Spam  \n",
       "0                          61                       278     1  \n",
       "1                         101                      1028     1  \n",
       "2                          40                       191     1  \n",
       "3                          15                        54     1  \n",
       "4                           4                       112     1  \n",
       "5                          11                        49     1  \n",
       "6                         445                      1257     1  \n",
       "7                          43                       749     1  \n",
       "8                           6                        21     1  \n",
       "9                          11                       184     1  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#Load data\n",
    "spam_train = pd.read_csv('spamdataset_train.csv')\n",
    "spam_test = pd.read_csv('spamdataset_test.csv')\n",
    "#split dataset\n",
    "test_features = spam_test\n",
    "train_target = spam_train['Spam']\n",
    "train_features = spam_train.drop('Spam', axis=1)\n",
    "spam_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC quality is : 83.2778147901%\n",
      "[0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluation of quality score\n",
    "# Split the train dataset in using cross validation method\n",
    "eval_features, test_eval_features, eval_target, test_eval_target = \\\n",
    "cross_validation.train_test_split(train_features, train_target, test_size=0.33)\n",
    "modelSVC = SVC()\n",
    "modelSVC.fit(eval_features, eval_target)\n",
    "resEval = modelSVC.predict(test_eval_features)\n",
    "score = accuracy_score(test_eval_target, resEval)\n",
    "print(\"SVC quality is : \" + str(score*100) + \"%\")\n",
    "\n",
    "# Prediction of test dataset \n",
    "modelSCV.fit(train_features, train_target)\n",
    "resSCV = modelSCV.predict(test_features)\n",
    "print(resSCV)\n",
    "# Add it as a new column\n",
    "spam_test['Spam'] = resSCV\n",
    "spam_test.to_csv('scvSapmTest.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART quality is 90.6728847435%\n",
      "[0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
      " 1 1 1 0 1 0 1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Evaluation of quality score\n",
    "eval_features, test_eval_features, eval_target, test_eval_target = \\\n",
    "cross_validation.train_test_split(train_features, train_target, test_size=0.33)\n",
    "modelTree = DecisionTreeClassifier()\n",
    "modelTree.fit(eval_features, eval_target)\n",
    "resTreeEval = modelTree.predict(test_eval_features)\n",
    "scoreTree = accuracy_score(test_eval_target, resTreeEval)\n",
    "print(\"CART quality is \" + str(scoreTree*100) + \"%\")\n",
    "\n",
    "# Prediction of test dataset\n",
    "modelSCV.fit(train_features, train_target)\n",
    "resTree = modelTree.predict(test_features)\n",
    "print(resTree)\n",
    "\n",
    "# Add it as a new column\n",
    "spam_test['Spam'] = resTree\n",
    "spam_test.to_csv('treeSapmTest.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native bayes in gausin quality is 80.6129247169%\n",
      "[0 0 1 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1\n",
      " 0 0 1 0 1 1 1 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#It runs quick, but a low quality\n",
    "\n",
    "#Evaluation of quality score\n",
    "eval_features, test_eval_features, eval_target, test_eval_target = \\\n",
    "cross_validation.train_test_split(train_features, train_target, test_size=0.33)\n",
    "modelGNB = GaussianNB()\n",
    "modelGNB.fit(eval_features, eval_target)\n",
    "resGNBEval = modelGNB.predict(test_eval_features)\n",
    "scoreGNB = accuracy_score(test_eval_target, resGNBEval)\n",
    "print(\"Native bayes in gausin quality is \" + str(scoreGNB*100) + \"%\")\n",
    "\n",
    "# Prediction of test dataset\n",
    "modelGNB.fit(train_features, train_target)\n",
    "resGNB = modelGNB.predict(test_features)\n",
    "print(resGNB)\n",
    "\n",
    "# Add it as a new column\n",
    "spam_test['Spam'] = resTree\n",
    "spam_test.to_csv('GNBSapmTest.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression quality is 93.4710193205%\n",
      "[0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Evaluation of quality score\n",
    "eval_features, test_eval_features, eval_target, test_eval_target = \\\n",
    "cross_validation.train_test_split(train_features, train_target, test_size=0.33)\n",
    "modelLR = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "modelLR.fit(eval_features, eval_target)\n",
    "resLREval = modelLR.predict(test_eval_features)\n",
    "scoreLR = accuracy_score(test_eval_target, resLREval)\n",
    "print(\"Logistic regression quality is \" + str(scoreLR*100) + \"%\")\n",
    "\n",
    "# Prediction of test dataset\n",
    "modelLR.fit(train_features, train_target)\n",
    "resLR = modelLR.predict(test_features)\n",
    "print(resLR)\n",
    "\n",
    "# Add it as a new column\n",
    "spam_test['Spam'] = resTree\n",
    "spam_test.to_csv('LRSapmTest.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Selon le résultat de chaque $\\hat{R}(f)$, la regression logistique a une meilleure qualité pour la prédiction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export result to csv\n",
    "data = {'result SCV':resSCV, 'result CART':resTree, 'result Native Bayes':resGNB, 'result logistic regression':resLR}\n",
    "resTotal = pd.DataFrame(data)\n",
    "resTotal.to_csv(\"ALL_RES.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
